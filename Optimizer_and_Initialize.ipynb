{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJpFhi3P5A8iUl1vkxC3Cg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DowookKim/Deep_learing/blob/master/Optimizer_and_Initialize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 옵티마이저"
      ],
      "metadata": {
        "id": "sUgtSNQhVxUu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 아다그라드(속도 조절, adaptive gradient)\n",
        "**w(i + 1) = w(i) -  {η / (G(i) + δ) ^^ 1/2 } * ∇E(w(i))**\n",
        "\n",
        "**G(i) = G(i - 1) + (∇E(w(i)))^^2**\n",
        "\n",
        "**아다그라드** 가중치의 누적된 값에 따라 학습률을 조정하는 방법\n",
        "**아다그라드**는 많이 변화하지 않는 가중치들의 학습률은 크게 하고 많이 변화하는 가중치들의 학습률은 작게 함. 즉, 많이 변화한 가중치는 최적 값에 근접 했을 것이라는 가정하게 작은 크기로 이동하면서 세밀하게 값을 조정하고 반대로 적게 변화한 가중치들은 학습률을 크게 하여 빠르게 오차 값을 줄이고자 함\n",
        "\n",
        "파라미터마다 다른 학습률을 주기 위해 G 함수 추가\n",
        "**G** = 이전 G값의 누적(기울크 크기의 누적)\n",
        "G가 커지면  (G(i) + δ) ^^ 1/2 의 값이 커져서 학습률은 작아진다.\n",
        "\n",
        "∇E(w(i))는 가중치가 w(i)일 때 gradient 값 = 가중치가 w(i)일 때 loss가 커지는 방향의 기울기 값\n",
        "\n",
        "E(w(i))는 가중치가 w(i)일 때 loss 값\n"
      ],
      "metadata": {
        "id": "mHckZI4Bti8p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 아다델타(속도조절, Adaptive delta)\n",
        "**아다델타**는 아다라드에서 G 값 즉, 기울기 크기의 누적값이 커짐에 따라 학습이 멈추는 것을 해결하기 위해서 등장\n",
        "\n",
        "**아다델타**는 아다그라드의 수식에서 학습률 η을 **D 함수**(가중치 변화량 **Δ** 크기를 누적한 값)으로 변환했기 때문에 학습률에 대한 하이퍼파라미터가 필요하지 않음\n",
        "\n",
        "**w(i + 1) = w(i) - ({D(i - 1) + δ} ^^1/2 )/ {G(i) + δ} ^^ 1/2  * ∇E(w(i))**\n",
        "\n",
        "**G(i) = ΓG(i -1) + (1 - Γ) * (∇E(w(i)))^^2**\n",
        "\n",
        "**D(i) = ΓD(i - 1) + (1 - Γ) * (Δ(w(i)))^^2**\n",
        "\n",
        "G(i)와 D(i)가 아다그라드와 다르게 누적합이 아니라 지수이동평균(Exponential Moving Average)가 사용되는 이유는 과거 정보값은 어느 정도 잊고 최신 경향만 반영해주자는 의미 -> 시간이 지날주록 G(i)가 무조건 커지면 학습률이 0에 가까워져서 학습을 하지 않아서 이 방법 도입\n"
      ],
      "metadata": {
        "id": "jcJ_aX3ty5q7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 알엠에스프롭(속조조절)\n",
        "**알엠에스프롭**은 아다그라드의 G(i)의 값이 무한히 커지는 것을 방지하고자 도입됨\n",
        "이것 또한 아다델타처럼 아다그라드에서 학습이 안되는 문제를 해결하기 위해 G 함수에서 **Γ**만 추가됨. G값이 너무 크면 학습률이 작아져서 학습이 안될 수 있으므로 사용자가 Γ값을 이용하여 학습률 크기를 비율로 조정할 수 있도록 함\n",
        "\n",
        "**w(i + 1) = w(i) - η / (G(i) + δ) * ∇E(w(i)**)\n",
        "\n",
        "**G(i) = Γ * G(i -1) + (1 -  Γ) * (∇E(w(i)))^^2**"
      ],
      "metadata": {
        "id": "eZNdUIJw56qc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**지금까지는 속도를 조절해서 가중치를 조절하는 방법이였고 지금부터는 모멘텀이라는 개념을 사용**\n",
        "\n",
        "**모멘텀**이란 경사 하강법과 마찬가지로 매번 기울기를 구하지만 가중치를 수정하기 전에 이전 수정 방향(+, -)을 참조하여 같은 방향으로 일정한 비율만 수정하는 방법임. 수정이 양의 방향과 음의 방향으로 순차적으로 일어나는 지그재그 현상이 줄어들고 이전 이동 값을 고려하여 일정 비율만큼 다음 값을 결정하므로 관성 효과를 얻을 수 있는 장점이 있음\n",
        "모멘텀은 SGD(확률적 경사 하강법)과 함께 사용된다\n",
        "\n",
        "먼저 확률적 경사 하강법의 수식이 다음과 같음\n",
        "w(i + 1) = w(i) - η * ∇E(w(i))"
      ],
      "metadata": {
        "id": "0e8-Z3ne-Ltl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SGD 모멘텀\n",
        "**SGD 모멘텀**은 확률적 경사 하가법에서 가울기(∇E(w(i)))를 **속도(v)**로 대체하여 사용하는 방식으로 이전 속도의 일정 부분을 반영\n",
        "\n",
        "즉, 이전에 학습했던 **속도**와 현재 기울기를 반영해서 가중치를 구함\n",
        "\n",
        "**w(i + 1) = w(i) - v(i)**\n",
        "\n",
        "**v(i) = Γ * v(i - 1) + η * ∇E(w(i))**\n",
        "\n",
        "관성이기 때문에 v(i)를 계산할 때 이전 속도 ,v(i - 1)를 더해야 함\n",
        "\n"
      ],
      "metadata": {
        "id": "CKZOJwTa8Kld"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 네스테로프 모멘텀\n",
        "**네스테로프 모멘텀**은 모멘텀 값과 기울기 값이 더해져 실제 값을 만드는 기존 모멘텀과 달리 모멘텀 값이 적용된 지점에서 기울기 값을 계산함\n",
        "\n",
        "모멘텀 방법은 멈추어야 할 시점에서도 관성에 의해 훨씬 멀리 갈 수 있는 단점이 있지만 **네스테로프 모멘텀** 모멘텀으로 미리 이동해본 다음에 어떤 방식으로 이동해야 하는지 다시 계산하여 결정하기 때문에 모멘텀 방법의 단점을 극복할 수 있음. 따라서 모멘텀 방법의 이점인 빠른 이동 속도는 그대로 가져가면서 멈추어야 할 적절한 시점에서 제동을 거는 데 훨씬 용이\n",
        "\n",
        "**w(i + 1) = w(i) - v(i)**\n",
        "\n",
        "**v(i) = Γv(i - 1) + η * ∇E(w(i) - Γ * v(i -1))**\n",
        "\n"
      ],
      "metadata": {
        "id": "BjE9C5Ngbxn1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 아담(속도와 운동량에 대한 혼용)\n",
        "**아담**은 **모멘텀**과 **알엠에스프롭**의 장점을 결합하 경사 하강법\n",
        "**알엠에스프롭** 특징인 기울기의 제곱을 지수평균한 값과 모멘텀 특징인 v(i)를 수식에 활용\n",
        "\n",
        "**w(i + 1) = w(i) - η * v(i) / (G(i) + δ)^^2/1**\n",
        "\n",
        "**G(i) = Γ2 * G(i - 1) + (1 - Γ2 ) * η * (∇E(w(i)))^^2**\n",
        "\n",
        "**v(i) = Γ1 * v(i - 1) + η * ∇E(w(i))**"
      ],
      "metadata": {
        "id": "nWFZw-lqg9ht"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 가중치 초기화\n",
        "가중치 초기화는 크게 **확률 분포 기반**의 **가중치 초기화와 **분산 조정** 기반의 초기화가 있음\n",
        "\n",
        "**확률 분포 기반**의 초기화는 특정한 확률 분포에 기반하여 랜덤한 값을 추출하여 가중치를 초기화 함. 여기서 균일 분포와 정규 분포가 사용된다. 정규 분포는 평균에 가까운 값일수록 더 높은 확률로 추출된다. 평균이 0, 표준편차가 0.05인 정규 분포에서 값을 추출하도록 설정되어 있음\n",
        "\n"
      ],
      "metadata": {
        "id": "jrYZITdgnEkU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "opCkaf_DYlx4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 분산 조정 기반의 초기화\n",
        "\n",
        "분산조정 기반의 초기화란 확률 분포를 기반으로 추출한 값으로 가중치를 초기화하되, 이 확률 분포의 분산을 가중치별로 동적으로 조절함. 그리고 분산을 조절할 때는 해당 가중치에 입력으로 들어오는 텐서의 차원(fan in)과 결과값으로 출력하는 텐서의 차원(fan out)이 사용됨\n",
        "\n"
      ],
      "metadata": {
        "id": "epjs0b33nxkA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LeCun 초기화 방식\n",
        "이 방식에는 lecun_uniform과 lecun_normal이 있음\n",
        "이 방식은 **입력 값의 차원이 커질수록 초기화 값의 분산을 작게 만든다**\n",
        "분산을 작게 만든다는 말보다 최대값과 최소값을 최대한 작게 만들어서 값이 커지는 것을 막아서 기울기 폭발 문제나 소실 문제 등을 해결함.\n",
        "차원이 커질수록 값이 커지는 이유는,\n",
        "출력 하나가 더 많은 독립적인 항들의 합으로 만들어지기 때문이며,\n",
        "이는 평균이 0이어도 피할 수 없는 현상이다.\n",
        "\n",
        "**lecun_uniform : unif(-limit, +limit), limit = (3 / fan_in) ^^ 1/2**\n",
        "\n",
        "**lecun_normal : normal(mean = 0, stddev), stddev = (1 / fan_in) ^^ 1/2**"
      ],
      "metadata": {
        "id": "Nls56HoypjIj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Xavier 초기화 방식\n",
        "이 방식에도 glorot_iniform과 glorot_normal이 있음\n",
        "이 방식은 fan_in과 fan_out을 모두 고려하여 확률 분포를계산함.\n",
        "Lecun 방식에서 2를 곱한 후 fan_in과 fan_out을 합한 크기로 나누어 준 값으로 확률 분포를 조정\n",
        "\n",
        "**glorot_uniform : unif(-limit, +limit), limit = (6 / (fan_in + fan_out)) ^^ 1/2**\n",
        "\n",
        "**glorot_normal : normal(mean = 0, stddev), stddev = (2 / fan_in + fan_out) ^^ 1/2**\n",
        "\n",
        "이 방식은 하이퍼볼릭 탄젠트를 활성화 함수로 사용하는 신경망에서 많이 사용된다. 하지만 렐루를 활성화 함수로 사용할 때는 잘 작동하지 않는 단점이 있음\n"
      ],
      "metadata": {
        "id": "xtkEs5VSwtA_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HE 초기화 방식\n",
        "이 방식에도 he_uniform과 he_normal이 있음. 이 방식은 Xavier 방식의 한계를 극복하려고 제안된 기법. 또한 ResNet을 학습시킬때 이 기법을 사용하여 실제로 CNN의 깊은 신경망을 잘 학습시킬 수 있음을 보여줌\n",
        "\n",
        "**he_uniform : unif(-limit, +limit), limit = (6 / fan_in) ^^ 1/2**\n",
        "\n",
        "**lhe_normal : normal(mean = 0, stddev), stddev = (2 / fan_in) ^^ 1/2**\n",
        "\n",
        "Xavier 방식에서 다시 fan_out을 제거함. 즉, fan_out보다 fan_in에 집중한 가중치로 이해하면 된다"
      ],
      "metadata": {
        "id": "SKRKKXOf15L5"
      }
    }
  ]
}